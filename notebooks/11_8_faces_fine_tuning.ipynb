{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 faces fine tuning \n",
    "In this nootebook we want to do some transfer learning to get a better classification performance on the data set with the 8 celebreties. For this we use a pretrained vgg16 network. We push each image through the trained VGG16 net and fetch the entries in the fc1 layer which we will use as CNN-feature representation of the respective image. The fetching of these CNN features is already done in another notbook (since loading of VGG16 including the top layer requires some time and space). Here we load '8_faces_EMB.npz' containing the CNN feature representation which were obtained by a pretrained VGG16. Then we train a fully connected network with these CNN-features and our own labels - this is called transfer learning since the feature extractor was learned on another data set (1 million images from iamgeNet with 1000 class labels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as imgplot\n",
    "import time\n",
    "%matplotlib inline\n",
    "import h5py\n",
    "from scipy import misc\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset that contains the CNN-feature representation of the 8-faces data set (because of computational reasons we just load them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading the data, if it does not exist\n",
    "import urllib\n",
    "import os\n",
    "if not os.path.isfile('8_faces_EMB.npz'):\n",
    "    urllib.request.urlretrieve(\n",
    "    \"https://www.dropbox.com/s/3w3x9i7ng7017l3/8_faces_EMB.npz?dl=1\",\n",
    "    \"8_faces_EMB.npz\")\n",
    "%ls -hl 8_faces_EMB.npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data=np.load(\"8_faces_EMB.npz\")\n",
    "print(Data.files)\n",
    "X_train = Data[\"arr_0\"]\n",
    "X_valid = Data[\"arr_1\"]\n",
    "X_test =  Data[\"arr_2\"]\n",
    "Y_train = Data[\"arr_3\"]\n",
    "Y_valid = Data[\"arr_4\"]\n",
    "Y_test =  Data[\"arr_5\"]\n",
    "print(X_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_valid.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToOneHot(vector, num_classes=None):\n",
    "    result = np.zeros((len(vector), num_classes), dtype='int32')\n",
    "    result[np.arange(len(vector)), vector] = 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train=convertToOneHot(Y_train,num_classes=8)\n",
    "Y_valid=convertToOneHot(Y_valid,num_classes=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Dense, Activation, Dropout, BatchNormalization\n",
    "from keras.models import Sequential\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "name = '8_faces_finetune'\n",
    "\n",
    "model.add(Dense(400,batch_input_shape=((None,4096))))\n",
    "# your code\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# end of your code\n",
    "\n",
    "\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = keras.callbacks.TensorBoard(\n",
    "        log_dir='tensorboard/8_faces/' + name + '/', \n",
    "        write_graph=True,\n",
    "        histogram_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit(X_train, Y_train, \n",
    "                  batch_size=128, \n",
    "                  epochs=30,\n",
    "                  verbose=2, \n",
    "                  validation_data=(X_valid, Y_valid),\n",
    "                  callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train acc', 'test acc'], loc='lower right')\n",
    "plt.show()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train loss', 'test loss'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation of the trained network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code, get the probabilities for each image of the test set \n",
    "preds_test="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "# your code, calculate the confusion matrix and the accuracy of the test set\n",
    "print(confusion_matrix())\n",
    "print(\"Acc = \" ,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading the data, if it does not exist\n",
    "if not os.path.isfile('8_faces_test.hdf5'):\n",
    "    urllib.request.urlretrieve(\n",
    "    \"https://www.dropbox.com/s/ugxrdo0lpc2ixvr/8_faces_test.hdf5?dl=1\",\n",
    "    \"8_faces_test.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5f_X = h5py.File('8_faces_test.hdf5', 'r')\n",
    "print(list(h5f_X.keys()))\n",
    "X_test = h5f_X['X_test_8_faces']\n",
    "print(X_test.shape)\n",
    "Y_test = h5f_X['Y_test_8_faces']\n",
    "print(Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize right and wrong classified images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=np.argmax(preds_test,axis=1)\n",
    "Klasse=1\n",
    "right = np.where(Y_test[:]==Klasse)[0][np.where(np.in1d(np.where(Y_test[:]==Klasse),np.where(pred[:]==Klasse)))]\n",
    "wrong = np.where(Y_test[:]==Klasse)[0][(np.in1d(np.where(Y_test[:]==Klasse),np.where(pred[:]==Klasse)))==False]\n",
    "\n",
    "plt.figure(figsize=(18,18))\n",
    "for i in range(0,len(right)):\n",
    "    plt.subplot(10,10,(i+1))\n",
    "    plt.imshow(np.asarray(X_test[right[i]],dtype=\"uint8\"))\n",
    "    plt.axis('off')\n",
    "    plt.title('right')\n",
    "    \n",
    "plt.figure(figsize=(18,18))\n",
    "for i in range(0,len(wrong)):\n",
    "    plt.subplot(10,10,(i+1))\n",
    "    plt.imshow(np.asarray(X_test[wrong[i]],dtype=\"uint8\"))\n",
    "    plt.axis('off')\n",
    "    plt.title('wrong')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
