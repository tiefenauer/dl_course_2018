{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tricks of the trade TF/Keras [small dataset]\n",
    "\n",
    "In this script we build a small multilayer perceptron with two hidden layers having 500 and 50 neurons each for classifying the MNIST database of handwritten digits using Keras. It uses a small data set so that it can be trained on the CPU.\n",
    "\n",
    "Below are several experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as imgplot\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(1)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, BatchNormalization\n",
    "import keras\n",
    "import sys\n",
    "print (\"Keras {} TF {} Python {}\".format(keras.__version__, tf.__version__, sys.version_info))\n",
    "\n",
    "# To be compatible with python3 and python2\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except ImportError:\n",
    "    import pickle\n",
    "import gzip\n",
    "\n",
    "with gzip.open('mnist_4000.pkl.gz', 'rb') as f:\n",
    "    if sys.version_info.major > 2:\n",
    "        (X,y) = pickle.load(f, encoding='latin1')\n",
    "    else:\n",
    "        (X,y) = pickle.load(f)\n",
    "PIXELS = len(X[0,0,0,:])\n",
    "\n",
    "print(X.shape, y.shape, PIXELS) #As read\n",
    "# We need to reshape for the MLP\n",
    "X = X.reshape([4000, 784])\n",
    "np.shape(X)\n",
    "\n",
    "# Taken from http://stackoverflow.com/questions/29831489/numpy-1-hot-array\n",
    "def convertToOneHot(vector, num_classes=None):\n",
    "    result = np.zeros((len(vector), num_classes), dtype='int32')\n",
    "    result[np.arange(len(vector)), vector] = 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suggestions for the experiment\n",
    "\n",
    "Let the experiments run for 100 epochs. You might need to restart the kernel so that namings of the layers are the same\n",
    "\n",
    "* with init zero \n",
    "* with sigmoid activation \n",
    "* with ReLU activation\n",
    "* with dropout (p=0.3)\n",
    "* with batch-normalization and dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### First model with all zeros\n",
    "name = 'sigmoid_init0'\n",
    "model = Sequential()\n",
    "model.add(Dense(500, batch_input_shape=(None, 784), init='zero'))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.add(Dense(50,init='zero'))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.add(Dense(10, activation='softmax',init='zero'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Untrained model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X[0:2000], convertToOneHot(y[0:2000],10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_classes(X[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tensorboard = keras.callbacks.TensorBoard(\n",
    "    log_dir='tensorboard/mnist_small/' + name + '/', \n",
    "    write_graph=True,\n",
    "    histogram_freq=1\n",
    ")\n",
    "history = model.fit(X[0:2400], \n",
    "          convertToOneHot(y[0:2400],10), \n",
    "          epochs=30, \n",
    "          batch_size=128, \n",
    "          callbacks=[tensorboard],\n",
    "          validation_data=[X[2400:3000], convertToOneHot(y[2400:3000],10)], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train acc', 'test acc'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train loss', 'test loss'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir=tensorboard/mnist_small/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
